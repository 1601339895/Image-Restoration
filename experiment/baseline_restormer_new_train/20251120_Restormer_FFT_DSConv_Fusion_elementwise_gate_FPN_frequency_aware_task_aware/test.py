# -*- coding: utf-8 -*-
# File  : FPN_Restormer_CA_CNN_Encoder.py
# Author: HeLei
# Date  : 2025/11/20

import torch
import torch.nn as nn
import torch.nn.functional as F
import math
from einops import rearrange
from torchsummary import summary  # ç”¨äºå‚æ•°é‡ç»Ÿè®¡
import cv2  # ç”¨äºå›¾åƒè¯»å–å’Œæ˜¾ç¤ºï¼ˆæµ‹è¯•ç”¨ï¼‰
import numpy as np
import numbers


##########################################################################
## åŸºç¡€å·¥å…·æ¨¡å—ï¼ˆæ¿€æ´»å‡½æ•°ã€å½’ä¸€åŒ–ç­‰ï¼‰
##########################################################################
# GELUæ¿€æ´»å‡½æ•°ï¼ˆç‹¬ç«‹å®ç°ï¼Œé¿å…ç‰ˆæœ¬ä¾èµ–ï¼‰
class GELU(nn.Module):
    def forward(self, x):
        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))


# LayerNormï¼ˆå¤ç”¨åŸRestormerä»£ç ï¼Œé€‚é…è§£ç å™¨ï¼‰
def to_3d(x):
    return rearrange(x, 'b c h w -> b (h w) c')


def to_4d(x, h, w):
    return rearrange(x, 'b (h w) c -> b c h w', h=h, w=w)


class BiasFree_LayerNorm(nn.Module):
    def __init__(self, normalized_shape):
        super(BiasFree_LayerNorm, self).__init__()
        if isinstance(normalized_shape, numbers.Integral):
            normalized_shape = (normalized_shape,)
        normalized_shape = torch.Size(normalized_shape)
        assert len(normalized_shape) == 1
        self.weight = nn.Parameter(torch.ones(normalized_shape))
        self.normalized_shape = normalized_shape

    def forward(self, x):
        sigma = x.var(-1, keepdim=True, unbiased=False)
        return x / torch.sqrt(sigma + 1e-5) * self.weight


class WithBias_LayerNorm(nn.Module):
    def __init__(self, normalized_shape):
        super(WithBias_LayerNorm, self).__init__()
        if isinstance(normalized_shape, numbers.Integral):
            normalized_shape = (normalized_shape,)
        normalized_shape = torch.Size(normalized_shape)
        assert len(normalized_shape) == 1
        self.weight = nn.Parameter(torch.ones(normalized_shape))
        self.bias = nn.Parameter(torch.zeros(normalized_shape))
        self.normalized_shape = normalized_shape

    def forward(self, x):
        mu = x.mean(-1, keepdim=True)
        sigma = x.var(-1, keepdim=True, unbiased=False)
        return (x - mu) / torch.sqrt(sigma + 1e-5) * self.weight + self.bias


class LayerNorm(nn.Module):
    def __init__(self, dim, LayerNorm_type):
        super(LayerNorm, self).__init__()
        if LayerNorm_type == 'BiasFree':
            self.body = BiasFree_LayerNorm(dim)
        else:
            self.body = WithBias_LayerNorm(dim)

    def forward(self, x):
        h, w = x.shape[-2:]
        return to_4d(self.body(to_3d(x)), h, w)


##########################################################################
## è§£ç å™¨ä¾èµ–æ¨¡å—ï¼ˆå¤ç”¨åŸRestormerï¼Œæ— ä¿®æ”¹ï¼‰
##########################################################################
class FeedForward(nn.Module):
    def __init__(self, dim, ffn_expansion_factor, bias):
        super(FeedForward, self).__init__()
        hidden_features = int(dim * ffn_expansion_factor)
        self.project_in = nn.Conv2d(dim, hidden_features * 2, kernel_size=1, bias=bias)
        self.dwconv = nn.Conv2d(hidden_features * 2, hidden_features * 2, kernel_size=3, stride=1, padding=1,
                                groups=hidden_features * 2, bias=bias)
        self.project_out = nn.Conv2d(hidden_features, dim, kernel_size=1, bias=bias)

    def forward(self, x):
        x = self.project_in(x)
        x1, x2 = self.dwconv(x).chunk(2, dim=1)
        x = F.gelu(x1) * x2
        x = self.project_out(x)
        return x


class Attention(nn.Module):
    def __init__(self, dim, num_heads, bias):
        super(Attention, self).__init__()
        self.num_heads = num_heads
        self.temperature = nn.Parameter(torch.ones(num_heads, 1, 1))
        self.qkv = nn.Conv2d(dim, dim * 3, kernel_size=1, bias=bias)
        self.qkv_dwconv = nn.Conv2d(dim * 3, dim * 3, kernel_size=3, stride=1, padding=1, groups=dim * 3, bias=bias)
        self.project_out = nn.Conv2d(dim, dim, kernel_size=1, bias=bias)

    def forward(self, x):
        b, c, h, w = x.shape
        qkv = self.qkv_dwconv(self.qkv(x))
        q, k, v = qkv.chunk(3, dim=1)
        q = rearrange(q, 'b (head c) h w -> b head c (h w)', head=self.num_heads)
        k = rearrange(k, 'b (head c) h w -> b head c (h w)', head=self.num_heads)
        v = rearrange(v, 'b (head c) h w -> b head c (h w)', head=self.num_heads)
        q = torch.nn.functional.normalize(q, dim=-1)
        k = torch.nn.functional.normalize(k, dim=-1)
        attn = (q @ k.transpose(-2, -1)) * self.temperature
        attn = attn.softmax(dim=-1)
        out = (attn @ v)
        out = rearrange(out, 'b head c (h w) -> b (head c) h w', head=self.num_heads, h=h, w=w)
        out = self.project_out(out)
        return out


class GatedMDTA(nn.Module):
    def __init__(self, dim, num_heads, bias, gate_type=None):
        super(GatedMDTA, self).__init__()
        self.num_heads = num_heads
        self.temperature = nn.Parameter(torch.ones(num_heads, 1, 1))
        self.gate_type = gate_type  # é—¨æ§ç±»å‹
        self.bias = bias
        self.dim = dim

        # 1. è®¡ç®—QKV+é—¨æ§åˆ†æ•°çš„æ€»é€šé“æ•°
        if gate_type is None:
            # æ— é—¨æ§ï¼šä¿æŒåŸMDTAçš„QKVé€šé“æ•°ï¼ˆdim*3ï¼‰
            self.qkv_out_channels = dim * 3
        elif gate_type == 'headwise':
            # Headwiseé—¨æ§ï¼šQé¢å¤–è¾“å‡ºnum_headsä¸ªé€šé“ï¼ˆæ¯ä¸ªå¤´1ä¸ªæ ‡é‡é—¨æ§ï¼‰
            # æ€»é€šé“æ•° = (Q+gate) + K + V = (dim + num_heads) + dim + dim = dim*3 + num_heads
            self.qkv_out_channels = dim * 3 + num_heads
        elif gate_type == 'elementwise':
            # Elementwiseé—¨æ§ï¼šQé¢å¤–è¾“å‡ºdimä¸ªé€šé“ï¼ˆä¸QåŒç»´åº¦ï¼Œé€å…ƒç´ é—¨æ§ï¼‰
            # æ€»é€šé“æ•° = (Q+gate) + K + V = (dim + dim) + dim + dim = dim*4
            self.qkv_out_channels = dim * 4
        else:
            raise ValueError(f"Unsupported gate_type: {gate_type}, choose from None, 'headwise', 'elementwise'")

        # 2. åˆå§‹åŒ–QKVæŠ•å½±ï¼ˆå«é—¨æ§åˆ†æ•°ï¼‰å’ŒDepthwise Convï¼ˆä¿æŒåŸMDTAç»“æ„ï¼‰
        self.qkv = nn.Conv2d(dim, self.qkv_out_channels, kernel_size=1, bias=bias)
        self.qkv_dwconv = nn.Conv2d(self.qkv_out_channels, self.qkv_out_channels, kernel_size=3, stride=1, padding=1,
                                    groups=self.qkv_out_channels, bias=bias)
        self.project_out = nn.Conv2d(dim, dim, kernel_size=1, bias=bias)

    def forward(self, x):
        b, c, h, w = x.shape  # è¾“å…¥ç»´åº¦ï¼š(batch, dim, height, width)
        head_dim = c // self.num_heads  # æ¯ä¸ªå¤´çš„ç»´åº¦

        # æ­¥éª¤1ï¼šQKV+é—¨æ§åˆ†æ•°çš„æŠ•å½±ä¸Depthwise Convï¼ˆä¿æŒåŸMDTAæµç¨‹ï¼‰
        qkv_with_gate = self.qkv_dwconv(self.qkv(x))  # (b, qkv_out_channels, h, w)

        # æ­¥éª¤2ï¼šæ‹†åˆ†Qã€Kã€Vå’Œé—¨æ§åˆ†æ•°
        if self.gate_type is None:
            # æ— é—¨æ§ï¼šç›´æ¥æ‹†åˆ†QKV
            q, k, v = qkv_with_gate.chunk(3, dim=1)  # q: (b, dim, h, w)
            gate_score = None
        elif self.gate_type == 'headwise':
            # Headwiseé—¨æ§ï¼šå…ˆæ‹†åˆ† (Q+gate)ã€Kã€Vï¼Œå†æ‹†åˆ†Qå’Œgate_score
            q_with_gate, k, v = qkv_with_gate.split([self.dim + self.num_heads, self.dim, self.dim],
                                                    dim=1)  # q_with_gate: (b, dim+num_heads, h, w)
            q, gate_score = q_with_gate.split([self.dim, self.num_heads],
                                              dim=1)  # q: (b, dim, h, w); gate_score: (b, num_heads, h, w)
        elif self.gate_type == 'elementwise':
            # Elementwiseé—¨æ§ï¼šå…ˆæ‹†åˆ† (Q+gate)ã€Kã€Vï¼Œå†æ‹†åˆ†Qå’Œgate_score
            q_with_gate, k, v = qkv_with_gate.split([self.dim * 2, self.dim, self.dim],
                                                    dim=1)  # q_with_gate: (b, 2*dim, h, w)
            q, gate_score = q_with_gate.chunk(2, dim=1)  # q: (b, dim, h, w); gate_score: (b, dim, h, w)

        # æ­¥éª¤3ï¼šæ³¨æ„åŠ›è®¡ç®—ï¼ˆä¿æŒåŸMDTAçš„è½¬ç½®æ³¨æ„åŠ›é€»è¾‘ï¼‰
        # ç»´åº¦é‡æ’ï¼š(b, dim, h, w) â†’ (b, num_heads, head_dim, h*w)
        q = rearrange(q, 'b (head c) h w -> b head c (h w)', head=self.num_heads, c=head_dim)
        k = rearrange(k, 'b (head c) h w -> b head c (h w)', head=self.num_heads, c=head_dim)
        v = rearrange(v, 'b (head c) h w -> b head c (h w)', head=self.num_heads, c=head_dim)

        # QKå½’ä¸€åŒ–ä¸æ³¨æ„åŠ›æƒé‡è®¡ç®—
        q = F.normalize(q, dim=-1)
        k = F.normalize(k, dim=-1)
        attn = (q @ k.transpose(-2, -1)) * self.temperature  # (b, head, h*w, h*w)
        attn = attn.softmax(dim=-1)

        # SDPAè¾“å‡ºï¼š(b, head, c, h*w)
        out = attn @ v  # (b, num_heads, head_dim, h*w)

        # æ­¥éª¤4ï¼šåº”ç”¨é—¨æ§ï¼ˆè®ºæ–‡æ ¸å¿ƒï¼šSDPAè¾“å‡ºåæ–½åŠ sigmoidä¹˜æ€§é—¨æ§ï¼‰
        if self.gate_type is not None:
            # è°ƒæ•´é—¨æ§åˆ†æ•°ç»´åº¦ï¼Œä¸outåŒ¹é…
            if self.gate_type == 'headwise':
                # Headwiseï¼šgate_score â†’ (b, num_heads, 1, h*w)ï¼ˆæ ‡é‡å¹¿æ’­åˆ°æ•´ä¸ªå¤´ç»´åº¦ï¼‰
                gate_score = rearrange(gate_score, 'b head h w -> b head 1 (h w)', head=self.num_heads)
            elif self.gate_type == 'elementwise':
                # Elementwiseï¼šgate_score â†’ (b, num_heads, head_dim, h*w)ï¼ˆä¸outå®Œå…¨åŒç»´åº¦ï¼‰
                gate_score = rearrange(gate_score, 'b (head c) h w -> b head c (h w)', head=self.num_heads, c=head_dim)

            # ä¹˜æ€§sigmoidé—¨æ§ï¼šåŠ¨æ€è¿‡æ»¤ä¿¡æ¯æµ
            out = out * torch.sigmoid(gate_score)

        # æ­¥éª¤5ï¼šç»´åº¦æ¢å¤ä¸è¾“å‡ºæŠ•å½±ï¼ˆä¿æŒåŸMDTAæµç¨‹ï¼‰
        out = rearrange(out, 'b head c (h w) -> b (head c) h w', head=self.num_heads, h=h, w=w)  # (b, dim, h, w)
        out = self.project_out(out)

        return out

class TransformerBlock(nn.Module):
    def __init__(self, dim, num_heads, ffn_expansion_factor, bias, LayerNorm_type,gate_type=None):
        super(TransformerBlock, self).__init__()
        self.norm1 = LayerNorm(dim, LayerNorm_type)
        # self.attn = Attention(dim, num_heads, bias)
        self.attn = GatedMDTA(dim, num_heads, bias, gate_type=gate_type)
        self.norm2 = LayerNorm(dim, LayerNorm_type)
        self.ffn = FeedForward(dim, ffn_expansion_factor, bias)

    def forward(self, x):
        x = x + self.attn(self.norm1(x))
        x = x + self.ffn(self.norm2(x))
        return x


##########################################################################
## ç¼–ç å™¨æ ¸å¿ƒæ¨¡å—ï¼ˆè½»é‡åŒ–FFT+æ·±åº¦å¯åˆ†ç¦»CNNï¼‰
##########################################################################
# ECAé€šé“æ³¨æ„åŠ›ï¼ˆè½»é‡ï¼Œé€‚é…concatèåˆï¼‰
class ECA(nn.Module):
    def __init__(self, channel, k_size=3):
        super(ECA, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        b, c, h, w = x.shape
        y = self.avg_pool(x).view(b, 1, c)
        y = self.conv(y).view(b, c, 1, 1)
        return x * self.sigmoid(y)


# æ·±åº¦å¯åˆ†ç¦»å·ç§¯å°è£…
class DepthwiseSeparableConv(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, dilation=1, bias=False):
        super(DepthwiseSeparableConv, self).__init__()
        self.depthwise = nn.Conv2d(
            in_channels, in_channels, kernel_size=kernel_size, stride=stride,
            padding=padding, dilation=dilation, groups=in_channels, bias=bias
        )
        self.pointwise = nn.Conv2d(
            in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=bias
        )

    def forward(self, x):
        return self.pointwise(self.depthwise(x))


# æ ¸å¿ƒï¼šè½»é‡åŒ–FFT-æ·±åº¦å¯åˆ†ç¦»CNN Blockï¼ˆåŸç‰ˆï¼Œä¿ç•™å¤‡ç”¨ï¼‰
class Light_FFT_DSConv_Block(nn.Module):
    def __init__(self, dim, bias, dilation_rate=1):
        super(Light_FFT_DSConv_Block, self).__init__()
        self.dim = dim
        self.half_dim = dim // 2  # ç©ºåŸŸ/é¢‘åŸŸå„å C/2é€šé“

        # ç©ºåŸŸåˆ†æ”¯
        self.spatial_branch = nn.Sequential(
            nn.BatchNorm2d(self.half_dim),
            GELU(),
            DepthwiseSeparableConv(
                in_channels=self.half_dim,
                out_channels=self.half_dim,
                kernel_size=3,
                padding=dilation_rate,
                dilation=dilation_rate,
                bias=bias
            ),
            nn.BatchNorm2d(self.half_dim)
        )

        # é¢‘åŸŸåˆ†æ”¯
        self.fft_branch = nn.Sequential(
            nn.Conv2d(dim, self.half_dim, kernel_size=1, bias=bias),  # å®éƒ¨+è™šéƒ¨ï¼ˆCé€šé“ï¼‰â†’ C/2
            nn.BatchNorm2d(self.half_dim),
            GELU(),
            DepthwiseSeparableConv(
                in_channels=self.half_dim,
                out_channels=self.half_dim,
                kernel_size=3,
                padding=dilation_rate,
                dilation=dilation_rate,
                bias=bias
            ),
            nn.BatchNorm2d(self.half_dim)
        )

        # èåˆ+é€šé“æ³¨æ„åŠ›
        self.eca = ECA(channel=dim)
        self.residual_conv = nn.Identity()

    def forward(self, x):
        residual = self.residual_conv(x)
        b, c, h, w = x.shape

        # é€šé“æ‹†åˆ†
        spatial_x, fft_x = x.chunk(2, dim=1)

        # ç©ºåŸŸåˆ†æ”¯å‰å‘
        spatial_out = self.spatial_branch(spatial_x)

        # é¢‘åŸŸåˆ†æ”¯å‰å‘
        fft = torch.fft.fft2(fft_x, dim=(-2, -1))
        fft_feat = torch.cat([fft.real, fft.imag], dim=1)
        fft_out = self.fft_branch(fft_feat)

        # èåˆ+æ³¨æ„åŠ›+æ®‹å·®
        fusion_out = torch.cat([spatial_out, fft_out], dim=1)
        fusion_out = self.eca(fusion_out)
        return fusion_out + residual


##########################################################################
## æ”¹è¿›ç‰ˆï¼šFrequencyAwareBlock - é¢‘ç‡æ„ŸçŸ¥ç¼–ç å™¨
##########################################################################
class FrequencyAwareBlock(nn.Module):
    """é¢‘ç‡æ„ŸçŸ¥å—ï¼šæ˜¾å¼å»ºæ¨¡ä½é¢‘/ä¸­é¢‘/é«˜é¢‘æˆåˆ†ï¼Œå¢å¼ºé¢‘åŸŸå¤„ç†èƒ½åŠ›

    æ”¹è¿›ç‚¹ï¼š
    1. ä½¿ç”¨é¢‘è°±å¹…åº¦å’Œç›¸ä½æ›¿ä»£ç®€å•çš„å®éƒ¨è™šéƒ¨æ‹¼æ¥
    2. é¢‘ç‡æ„ŸçŸ¥é—¨æ§ï¼šè‡ªé€‚åº”è°ƒæ•´ä½é¢‘/é«˜é¢‘æƒé‡
    3. è·¨åŸŸäº¤äº’æ³¨æ„åŠ›ï¼šåŠ¨æ€å¹³è¡¡ç©ºåŸŸ-é¢‘åŸŸç‰¹å¾
    4. ä»»åŠ¡è‡ªé€‚åº”è†¨èƒ€å·ç§¯ï¼šæ ¹æ®ç‰¹å¾è‡ªé€‚åº”è°ƒæ•´æ„Ÿå—é‡

    å†…å­˜ä¼˜åŒ–ï¼š
    - å‡å°‘ä¸­é—´å±‚é€šé“æ•°ï¼ˆé¢‘ç‡é—¨æ§å’Œè·¨åŸŸæ³¨æ„åŠ›é™ç»´åˆ°1/4å’Œ1/8ï¼‰
    - ä½¿ç”¨in-placeæ“ä½œå‡å°‘å†…å­˜åˆ†é…
    - å¯é€‰ç®€åŒ–æ¨¡å¼ï¼šlightweight=Trueæ—¶ä½¿ç”¨æ›´è½»é‡çš„å®ç°
    """
    def __init__(self, dim, bias=False, dilation_rate=1, lightweight=False):
        super(FrequencyAwareBlock, self).__init__()
        self.dim = dim
        self.half_dim = dim // 2
        self.dilation_rate = dilation_rate
        self.lightweight = lightweight

        # ===== ä¼˜åŒ–1ï¼šç©ºåŸŸåˆ†æ”¯ï¼ˆä¿æŒåŸæœ‰è®¾è®¡ï¼Œæ·»åŠ ä»»åŠ¡è‡ªé€‚åº”è†¨èƒ€ï¼‰ =====
        self.spatial_branch = nn.Sequential(
            nn.BatchNorm2d(self.half_dim),
            GELU(),
            DepthwiseSeparableConv(
                in_channels=self.half_dim,
                out_channels=self.half_dim,
                kernel_size=3,
                padding=dilation_rate,
                dilation=dilation_rate,
                bias=bias
            ),
            nn.BatchNorm2d(self.half_dim)
        )

        # ===== ä¼˜åŒ–2ï¼šå¢å¼ºé¢‘åŸŸåˆ†æ”¯ =====
        # 2.1 é¢‘è°±å¹…åº¦+ç›¸ä½æå–ï¼ˆæ›¿ä»£ç®€å•çš„å®éƒ¨è™šéƒ¨æ‹¼æ¥ï¼‰
        self.fft_mag_phase_extract = nn.Sequential(
            nn.Conv2d(dim, self.half_dim, kernel_size=1, bias=bias),  # å¹…åº¦+ç›¸ä½ â†’ C/2
            nn.BatchNorm2d(self.half_dim),
            GELU()
        )

        # 2.2 é¢‘ç‡æ„ŸçŸ¥é—¨æ§ï¼šè‡ªé€‚åº”ä½é¢‘/é«˜é¢‘æƒé‡ï¼ˆä¼˜åŒ–ï¼šå‡å°‘ä¸­é—´å±‚é€šé“æ•°ï¼‰
        self.freq_gate = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),  # å…¨å±€æ± åŒ–æ•è·é¢‘ç‡åˆ†å¸ƒç‰¹æ€§
            nn.Conv2d(self.half_dim, self.half_dim // 4, kernel_size=1, bias=bias),  # é™ç»´åˆ°1/4
            GELU(),
            nn.Conv2d(self.half_dim // 4, self.half_dim * 2, kernel_size=1, bias=bias),  # è¾“å‡ºä½é¢‘/é«˜é¢‘æƒé‡
            nn.Sigmoid()
        )

        # 2.3 é¢‘åŸŸæ·±åº¦å·ç§¯å¤„ç†
        self.fft_conv = nn.Sequential(
            DepthwiseSeparableConv(
                in_channels=self.half_dim,
                out_channels=self.half_dim,
                kernel_size=3,
                padding=dilation_rate,
                dilation=dilation_rate,
                bias=bias
            ),
            nn.BatchNorm2d(self.half_dim)
        )

        # ===== ä¼˜åŒ–3ï¼šè·¨åŸŸäº¤äº’æ³¨æ„åŠ›ï¼ˆä¼˜åŒ–ï¼šè¿›ä¸€æ­¥é™ç»´å‡å°‘è®¡ç®—é‡ï¼‰ =====
        # åœ¨lightweightæ¨¡å¼ä¸‹ï¼Œå¯ä»¥é€‰æ‹©ç¦ç”¨è·¨åŸŸæ³¨æ„åŠ›ä»¥èŠ‚çœæ›´å¤šå†…å­˜
        if not lightweight:
            self.cross_domain_attn = nn.Sequential(
                nn.Conv2d(dim, dim // 8, kernel_size=1, bias=bias),  # é™ç»´åˆ°1/8
                GELU(),
                nn.Conv2d(dim // 8, dim, kernel_size=1, bias=bias),
                nn.Sigmoid()
            )
        else:
            self.cross_domain_attn = None

        # èåˆ+é€šé“æ³¨æ„åŠ›ï¼ˆä¿ç•™åŸæœ‰ECAï¼‰
        self.eca = ECA(channel=dim)

    def forward(self, x):
        residual = x
        b, c, h, w = x.shape

        # é€šé“æ‹†åˆ†
        spatial_x, freq_x = x.chunk(2, dim=1)

        # ===== ç©ºåŸŸåˆ†æ”¯å¤„ç† =====
        spatial_out = self.spatial_branch(spatial_x)

        # ===== å¢å¼ºé¢‘åŸŸåˆ†æ”¯å¤„ç† =====
        # 1. FFTå˜æ¢
        fft = torch.fft.fft2(freq_x, dim=(-2, -1))

        # 2. æå–é¢‘è°±å¹…åº¦å’Œç›¸ä½ï¼ˆæ›¿ä»£ç®€å•çš„å®éƒ¨è™šéƒ¨æ‹¼æ¥ï¼‰
        fft_mag = torch.abs(fft)  # é¢‘è°±å¹…åº¦ (B, C/2, H, W)
        fft_phase = torch.angle(fft)  # ç›¸ä½ä¿¡æ¯ (B, C/2, H, W)
        # æ‹¼æ¥å¹…åº¦å’Œç›¸ä½ä½œä¸ºé¢‘åŸŸç‰¹å¾
        fft_mag_phase = torch.cat([fft_mag, fft_phase], dim=1)  # (B, C, H, W)

        # 3. å¹…åº¦+ç›¸ä½ç‰¹å¾æå–ï¼ˆå°†Cé€šé“é™åˆ°C/2ï¼‰
        fft_feat = self.fft_mag_phase_extract(fft_mag_phase)  # (B, C/2, H, W)

        # 4. é¢‘ç‡æ„ŸçŸ¥é—¨æ§ï¼šè‡ªé€‚åº”ä½é¢‘/é«˜é¢‘åˆ†ç¦»ï¼ˆä¼˜åŒ–ï¼šä½¿ç”¨in-placeæ“ä½œå‡å°‘å†…å­˜ï¼‰
        freq_weights = self.freq_gate(fft_feat)  # (B, C, 1, 1) - è¾“å‡ºCé€šé“ç”¨äºåˆ†æˆlow/highå„C/2
        low_freq_weight, high_freq_weight = freq_weights.chunk(2, dim=1)  # å„(B, C/2, 1, 1)

        # 5. ä½é¢‘/é«˜é¢‘åˆ†ç¦»å¤„ç†ï¼ˆä¼˜åŒ–ï¼šå‡å°‘ä¸­é—´å¼ é‡ï¼‰
        # ä½é¢‘è¿‘ä¼¼ï¼šä½¿ç”¨å¹³å‡æ± åŒ–å¹³æ»‘
        fft_smooth = F.avg_pool2d(fft_feat, kernel_size=3, stride=1, padding=1)  # ä½é¢‘æˆåˆ† (B, C/2, H, W)
        # é«˜é¢‘ç»†èŠ‚ï¼šåŸå§‹ç‰¹å¾å‡å»ä½é¢‘ï¼ˆin-placeæ“ä½œï¼‰
        fft_detail = fft_feat - fft_smooth  # é«˜é¢‘æˆåˆ† (B, C/2, H, W)
        # åŠ æƒèåˆï¼šæ ¹æ®é—¨æ§æƒé‡åŠ¨æ€å¹³è¡¡ä½é¢‘/é«˜é¢‘ï¼ˆå¤ç”¨fft_featå†…å­˜ï¼‰
        fft_weighted = low_freq_weight * fft_smooth
        fft_weighted.add_(high_freq_weight * fft_detail)  # in-place add

        # 6. é¢‘åŸŸå·ç§¯å¤„ç†
        fft_out = self.fft_conv(fft_weighted)  # (B, C/2, H, W)

        # ===== è·¨åŸŸäº¤äº’èåˆ =====
        # æ‹¼æ¥ç©ºåŸŸ+é¢‘åŸŸç‰¹å¾
        fusion = torch.cat([spatial_out, fft_out], dim=1)

        # è·¨åŸŸäº¤äº’æ³¨æ„åŠ›ï¼šåŠ¨æ€è°ƒæ•´åŒåŸŸæƒé‡ï¼ˆlightweightæ¨¡å¼ä¸‹è·³è¿‡ï¼‰
        if self.cross_domain_attn is not None:
            cross_attn = self.cross_domain_attn(fusion)
            fusion_out = fusion * cross_attn
        else:
            fusion_out = fusion

        # é€šé“æ³¨æ„åŠ›å¢å¼º
        fusion_out = self.eca(fusion_out)

        return fusion_out + residual


##########################################################################
## å¤šå°ºåº¦èåˆæ¨¡å—ï¼ˆFPN/PAFPNï¼‰
##########################################################################
# ä¸‹é‡‡æ ·/ä¸Šé‡‡æ ·æ¨¡å—ï¼ˆå¤ç”¨åŸRestormerï¼Œç¡®ä¿ä¸€è‡´æ€§ï¼‰
class Downsample(nn.Module):
    def __init__(self, n_feat):
        super(Downsample, self).__init__()
        self.body = nn.Sequential(
            nn.Conv2d(n_feat, n_feat // 2, kernel_size=3, stride=1, padding=1, bias=False),
            nn.PixelUnshuffle(2)
        )

    def forward(self, x):
        return self.body(x)


# FPN/PAFPNä¸“ç”¨ä¸‹é‡‡æ ·ï¼ˆä¿æŒé€šé“æ•°ä¸å˜ï¼‰
class DownsampleKeepChannels(nn.Module):
    def __init__(self, n_feat):
        super(DownsampleKeepChannels, self).__init__()
        self.body = nn.Sequential(
            nn.Conv2d(n_feat, n_feat // 4, kernel_size=3, stride=1, padding=1, bias=False),
            nn.PixelUnshuffle(2)  # (n_feat//4) * 4 = n_feat (ä¿æŒé€šé“æ•°)
        )

    def forward(self, x):
        return self.body(x)


class Upsample(nn.Module):
    def __init__(self, n_feat):
        super(Upsample, self).__init__()
        self.body = nn.Sequential(
            nn.Conv2d(n_feat, n_feat * 2, kernel_size=3, stride=1, padding=1, bias=False),
            nn.PixelShuffle(2)
        )

    def forward(self, x):
        return self.body(x)


# FPN/PAFPNä¸“ç”¨ä¸Šé‡‡æ ·ï¼ˆä¿æŒé€šé“æ•°ä¸å˜ï¼‰
class UpsampleKeepChannels(nn.Module):
    def __init__(self, n_feat):
        super(UpsampleKeepChannels, self).__init__()
        self.body = nn.Sequential(
            nn.Conv2d(n_feat, n_feat * 4, kernel_size=3, stride=1, padding=1, bias=False),
            nn.PixelShuffle(2)  # 4*n_feat / 4 = n_feat (ä¿æŒé€šé“æ•°)
        )

    def forward(self, x):
        return self.body(x)


# FPNèåˆæ¨¡å—ï¼ˆè‡ªä¸Šè€Œä¸‹ï¼‰
class FPN_Fusion(nn.Module):
    def __init__(self, dims=[48, 96, 192, 384], bias=False):
        super(FPN_Fusion, self).__init__()
        self.dims = dims  # [level1, level2, level3, latent]
        self.lateral_convs = nn.ModuleList([
            nn.Conv2d(dims[i], dims[1], kernel_size=1, bias=bias) for i in range(4)
        ])
        # ä¸Šé‡‡æ ·å±‚ï¼šä½¿ç”¨ä¿æŒé€šé“æ•°çš„ä¸Šé‡‡æ ·ï¼ˆå› ä¸ºlateral_convså·²å°†æ‰€æœ‰ç‰¹å¾ç»Ÿä¸€åˆ°dims[1]=96ï¼‰
        self.upsamples = nn.ModuleList([
            UpsampleKeepChannels(dims[1]),  # è¾“å…¥96é€šé“ï¼Œè¾“å‡º96é€šé“
            UpsampleKeepChannels(dims[1]),
            UpsampleKeepChannels(dims[1])
        ])
        self.output_convs = nn.ModuleList([
            nn.Conv2d(dims[1], dims[i], kernel_size=3, stride=1, padding=1, bias=bias) for i in range(4)
        ])

    def forward(self, features):
        # features: [level1, level2, level3, latent]
        lateral_feats = [conv(feat) for conv, feat in zip(self.lateral_convs, features)]

        # è‡ªä¸Šè€Œä¸‹èåˆï¼šlatent -> level3 -> level2 -> level1
        fused_feats = [lateral_feats[3]]  # ä»latentå¼€å§‹

        # latent -> level3
        up_feat = self.upsamples[0](fused_feats[0])  # ä¸Šé‡‡æ ·latent
        fused = up_feat + lateral_feats[2]  # ä¸level3èåˆ
        fused_feats.append(fused)

        # level3 -> level2
        up_feat = self.upsamples[1](fused_feats[1])  # ä¸Šé‡‡æ ·level3
        fused = up_feat + lateral_feats[1]  # ä¸level2èåˆ
        fused_feats.append(fused)

        # level2 -> level1
        up_feat = self.upsamples[2](fused_feats[2])  # ä¸Šé‡‡æ ·level2
        fused = up_feat + lateral_feats[0]  # ä¸level1èåˆ
        fused_feats.append(fused)

        fused_feats = fused_feats[::-1]  # æ¢å¤ä¸º[level1, level2, level3, latent]
        output_feats = [conv(feat) for conv, feat in zip(self.output_convs, fused_feats)]
        return output_feats


# PAFPNèåˆæ¨¡å—ï¼ˆFPN+è‡ªä¸‹è€Œä¸Šå¢å¼ºï¼‰+ ä»»åŠ¡æ„ŸçŸ¥æƒé‡
class PAFPN_Fusion(nn.Module):
    def __init__(self, dims=[48, 96, 192, 384], bias=False, task_aware=True):
        super(PAFPN_Fusion, self).__init__()
        self.dims = dims
        self.task_aware = task_aware

        self.lateral_convs = nn.ModuleList([
            nn.Conv2d(dims[i], dims[1], kernel_size=1, bias=bias) for i in range(4)
        ])
        # ä¸Šé‡‡æ ·å±‚ï¼šä½¿ç”¨ä¿æŒé€šé“æ•°çš„ä¸Šé‡‡æ ·
        self.upsamples = nn.ModuleList([
            UpsampleKeepChannels(dims[1]),  # è¾“å…¥96é€šé“ï¼Œè¾“å‡º96é€šé“
            UpsampleKeepChannels(dims[1]),
            UpsampleKeepChannels(dims[1])
        ])
        # ä¸‹é‡‡æ ·å±‚ï¼šä½¿ç”¨ä¿æŒé€šé“æ•°çš„ä¸‹é‡‡æ ·
        self.downsamples = nn.ModuleList([
            DownsampleKeepChannels(dims[1]),  # è¾“å…¥96é€šé“ï¼Œè¾“å‡º96é€šé“
            DownsampleKeepChannels(dims[1])
        ])
        self.output_convs = nn.ModuleList([
            nn.Conv2d(dims[1], dims[i], kernel_size=3, stride=1, padding=1, bias=bias) for i in range(4)
        ])

        # ===== ä¼˜åŒ–3ï¼šä»»åŠ¡æ„ŸçŸ¥çš„å¤šå°ºåº¦èåˆæƒé‡ =====
        if task_aware:
            # ä¸ºæ¯ä¸ªå°ºåº¦å­¦ä¹ è‡ªé€‚åº”æƒé‡ï¼ˆæ ¹æ®è¾“å…¥å†…å®¹åŠ¨æ€è°ƒæ•´ï¼‰
            self.scale_attn = nn.ModuleList([
                nn.Sequential(
                    nn.AdaptiveAvgPool2d(1),
                    nn.Conv2d(dims[i], dims[i] // 4, kernel_size=1, bias=bias),
                    GELU(),
                    nn.Conv2d(dims[i] // 4, dims[i], kernel_size=1, bias=bias),
                    nn.Sigmoid()
                ) for i in range(4)
            ])

    def forward(self, features):
        # ===== ä»»åŠ¡æ„ŸçŸ¥ï¼šä¸ºä¸åŒå°ºåº¦ç‰¹å¾æ·»åŠ è‡ªé€‚åº”æƒé‡ =====
        if self.task_aware:
            weighted_features = []
            for feat, attn_module in zip(features, self.scale_attn):
                scale_weight = attn_module(feat)
                weighted_features.append(feat * scale_weight)
            features = weighted_features

        # æ­¥éª¤1ï¼šä¾§å‘å·ç§¯ç»Ÿä¸€é€šé“åˆ°dims[1]
        lateral_feats = [conv(feat) for conv, feat in zip(self.lateral_convs, features)]

        # æ­¥éª¤2ï¼šè‡ªä¸Šè€Œä¸‹èåˆï¼ˆTop-Downï¼‰
        fused_feats = [lateral_feats[3]]  # ä»latentå¼€å§‹

        # latent -> level3
        up_feat = self.upsamples[0](fused_feats[0])
        fused = up_feat + lateral_feats[2]
        fused_feats.append(fused)

        # level3 -> level2
        up_feat = self.upsamples[1](fused_feats[1])
        fused = up_feat + lateral_feats[1]
        fused_feats.append(fused)

        # level2 -> level1
        up_feat = self.upsamples[2](fused_feats[2])
        fused = up_feat + lateral_feats[0]
        fused_feats.append(fused)

        fused_feats = fused_feats[::-1]  # [level1, level2, level3, latent]

        # æ­¥éª¤3ï¼šè‡ªä¸‹è€Œä¸Šå¢å¼ºï¼ˆBottom-Upï¼‰
        enhanced_feats = [fused_feats[0]]  # ä»level1å¼€å§‹

        # level1 -> level2
        down_feat = self.downsamples[0](enhanced_feats[0])
        enhanced = down_feat + fused_feats[1]
        enhanced_feats.append(enhanced)

        # level2 -> level3
        down_feat = self.downsamples[1](enhanced_feats[1])
        enhanced = down_feat + fused_feats[2]
        enhanced_feats.append(enhanced)

        enhanced_feats.append(fused_feats[3])  # ä¿æŒlatentä¸å˜

        # æ­¥éª¤4ï¼šæ¢å¤åŸå§‹é€šé“
        output_feats = [conv(feat) for conv, feat in zip(self.output_convs, enhanced_feats)]
        return output_feats


##########################################################################
## Patch Embeddingï¼ˆå¤ç”¨åŸRestormerï¼‰
##########################################################################
class OverlapPatchEmbed(nn.Module):
    def __init__(self, in_c=3, embed_dim=48, bias=False):
        super(OverlapPatchEmbed, self).__init__()
        self.proj = nn.Conv2d(in_c, embed_dim, kernel_size=3, stride=1, padding=1, bias=bias)

    def forward(self, x):
        return self.proj(x)


##########################################################################
## æœ€ç»ˆæ¨¡å‹ï¼šFrequencyAwareç¼–ç å™¨ + FPN/PAFPN + Transformerè§£ç å™¨
##########################################################################
class Restormer_FFT_DSConv_Fusion(nn.Module):
    def __init__(self,
                 inp_channels=3,
                 out_channels=3,
                 dim=48,
                 num_blocks=[4, 6, 6, 8],  # [level1, level2, level3, latent]çš„Blockæ•°
                 num_refinement_blocks=4,
                 heads=[1, 2, 4, 8],  # è§£ç å™¨æ³¨æ„åŠ›å¤´æ•°
                 ffn_expansion_factor=2.66,
                 bias=False,
                 LayerNorm_type='WithBias',
                 dual_pixel_task=False,
                 fusion_type='PAFPN',  # å¯é€‰ï¼š'None'ï¼ˆæ— èåˆï¼‰ã€'FPN'ã€'PAFPN'
                 gate_type = None,  ## å…¨å±€é—¨æ§ç±»å‹ï¼šNone/'headwise'/'elementwise'
                 use_frequency_aware=True,  # æ˜¯å¦ä½¿ç”¨FrequencyAwareBlock
                 task_aware_fusion=True,  # æ˜¯å¦ä½¿ç”¨ä»»åŠ¡æ„ŸçŸ¥èåˆ
                 lightweight_encoder=False,  # æ˜¯å¦ä½¿ç”¨è½»é‡çº§FrequencyAwareBlockï¼ˆç¦ç”¨è·¨åŸŸæ³¨æ„åŠ›ï¼‰
                 ):
        super(Restormer_FFT_DSConv_Fusion, self).__init__()

        self.gate_type = gate_type
        self.fusion_type = fusion_type
        self.dual_pixel_task = dual_pixel_task
        self.use_frequency_aware = use_frequency_aware

        # 1. Patch Embedding
        self.patch_embed = OverlapPatchEmbed(inp_channels, dim)

        # 2. ç¼–ç å™¨é€‰æ‹©ï¼šFrequencyAwareBlock æˆ– Light_FFT_DSConv_Block
        # ===== ä¼˜åŒ–2ï¼šä»»åŠ¡è‡ªé€‚åº”è†¨èƒ€ç‡ï¼ˆä¸åŒå±‚çº§ä¸åŒè†¨èƒ€ç‡ï¼‰=====
        # level1: å°è†¨èƒ€ç‡(1) - é€‚åˆå»å™ªç­‰å±€éƒ¨ä»»åŠ¡
        # level2: ä¸­è†¨èƒ€ç‡(2) - å¹³è¡¡å±€éƒ¨å’Œå…¨å±€
        # level3: å¤§è†¨èƒ€ç‡(4) - é€‚åˆå»é›¨ç­‰éœ€è¦å¤§æ„Ÿå—é‡çš„ä»»åŠ¡
        # latent: æœ€å¤§è†¨èƒ€ç‡(8) - æ•è·å…¨å±€ä¸Šä¸‹æ–‡
        if use_frequency_aware:
            block_cls = FrequencyAwareBlock
            block_kwargs = {'lightweight': lightweight_encoder}
        else:
            block_cls = Light_FFT_DSConv_Block
            block_kwargs = {}

        self.encoder_level1 = nn.Sequential(*[
            block_cls(dim=dim, bias=bias, dilation_rate=1, **block_kwargs)
            for _ in range(num_blocks[0])
        ])
        self.down1_2 = Downsample(dim)
        self.encoder_level2 = nn.Sequential(*[
            block_cls(dim=int(dim * 2 ** 1), bias=bias, dilation_rate=2, **block_kwargs)
            for _ in range(num_blocks[1])
        ])
        self.down2_3 = Downsample(int(dim * 2 ** 1))
        self.encoder_level3 = nn.Sequential(*[
            block_cls(dim=int(dim * 2 ** 2), bias=bias, dilation_rate=4, **block_kwargs)
            for _ in range(num_blocks[2])
        ])
        self.down3_4 = Downsample(int(dim * 2 ** 2))
        self.latent = nn.Sequential(*[
            block_cls(dim=int(dim * 2 ** 3), bias=bias, dilation_rate=8, **block_kwargs)
            for _ in range(num_blocks[3])
        ])

        # 3. å¤šå°ºåº¦ç‰¹å¾èåˆï¼ˆFPN/PAFPNï¼‰
        if fusion_type in ['FPN', 'PAFPN']:
            dims = [dim, int(dim * 2 ** 1), int(dim * 2 ** 2), int(dim * 2 ** 3)]
            if fusion_type == 'FPN':
                self.feature_fusion = FPN_Fusion(dims=dims, bias=bias)
            else:  # PAFPN
                self.feature_fusion = PAFPN_Fusion(dims=dims, bias=bias, task_aware=task_aware_fusion)
        else:
            self.feature_fusion = None  # æ— èåˆ

        # 4. è§£ç å™¨ï¼ˆå¤ç”¨åŸRestormerï¼‰
        self.up4_3 = Upsample(int(dim * 2 ** 3))
        self.reduce_chan_level3 = nn.Conv2d(int(dim * 2 ** 3), int(dim * 2 ** 2), kernel_size=1, bias=bias)
        self.decoder_level3 = nn.Sequential(*[
            TransformerBlock(dim=int(dim * 2 ** 2), num_heads=heads[2], ffn_expansion_factor=ffn_expansion_factor,
                             bias=bias, LayerNorm_type=LayerNorm_type, gate_type=gate_type)
            for _ in range(num_blocks[2])
        ])

        self.up3_2 = Upsample(int(dim * 2 ** 2))
        self.reduce_chan_level2 = nn.Conv2d(int(dim * 2 ** 2), int(dim * 2 ** 1), kernel_size=1, bias=bias)
        self.decoder_level2 = nn.Sequential(*[
            TransformerBlock(dim=int(dim * 2 ** 1), num_heads=heads[1], ffn_expansion_factor=ffn_expansion_factor,
                             bias=bias, LayerNorm_type=LayerNorm_type, gate_type=gate_type)
            for _ in range(num_blocks[1])
        ])

        self.up2_1 = Upsample(int(dim * 2 ** 1))
        self.decoder_level1 = nn.Sequential(*[
            TransformerBlock(dim=int(dim * 2 ** 1), num_heads=heads[0], ffn_expansion_factor=ffn_expansion_factor,
                             bias=bias, LayerNorm_type=LayerNorm_type, gate_type=gate_type)
            for _ in range(num_blocks[0])
        ])

        # 5. ç»†åŒ–æ¨¡å—
        self.refinement = nn.Sequential(*[
            TransformerBlock(dim=int(dim * 2 ** 1), num_heads=heads[0], ffn_expansion_factor=ffn_expansion_factor,
                             bias=bias, LayerNorm_type=LayerNorm_type, gate_type=gate_type)
            for _ in range(num_refinement_blocks)
        ])

        # 6. è¾“å‡ºå±‚
        if self.dual_pixel_task:
            self.skip_conv = nn.Conv2d(dim, int(dim * 2 ** 1), kernel_size=1, bias=bias)
        self.output = nn.Conv2d(int(dim * 2 ** 1), out_channels, kernel_size=3, stride=1, padding=1, bias=bias)

    def forward(self, inp_img):
        # 1. ç¼–ç å™¨å‰å‘
        inp_enc_level1 = self.patch_embed(inp_img)
        out_enc_level1 = self.encoder_level1(inp_enc_level1)

        inp_enc_level2 = self.down1_2(out_enc_level1)
        out_enc_level2 = self.encoder_level2(inp_enc_level2)

        inp_enc_level3 = self.down2_3(out_enc_level2)
        out_enc_level3 = self.encoder_level3(inp_enc_level3)

        inp_enc_level4 = self.down3_4(out_enc_level3)
        latent = self.latent(inp_enc_level4)

        # 2. ç‰¹å¾èåˆï¼ˆå¯é€‰ï¼‰
        if self.fusion_type in ['FPN', 'PAFPN']:
            features = [out_enc_level1, out_enc_level2, out_enc_level3, latent]
            fused_level1, fused_level2, fused_level3, fused_latent = self.feature_fusion(features)
        else:
            fused_level1, fused_level2, fused_level3, fused_latent = out_enc_level1, out_enc_level2, out_enc_level3, latent

        # 3. è§£ç å™¨å‰å‘
        inp_dec_level3 = self.up4_3(fused_latent)
        inp_dec_level3 = torch.cat([inp_dec_level3, fused_level3], 1)
        inp_dec_level3 = self.reduce_chan_level3(inp_dec_level3)
        out_dec_level3 = self.decoder_level3(inp_dec_level3)

        inp_dec_level2 = self.up3_2(out_dec_level3)
        inp_dec_level2 = torch.cat([inp_dec_level2, fused_level2], 1)
        inp_dec_level2 = self.reduce_chan_level2(inp_dec_level2)
        out_dec_level2 = self.decoder_level2(inp_dec_level2)

        inp_dec_level1 = self.up2_1(out_dec_level2)
        inp_dec_level1 = torch.cat([inp_dec_level1, fused_level1], 1)
        out_dec_level1 = self.decoder_level1(inp_dec_level1)

        out_dec_level1 = self.refinement(out_dec_level1)

        # 4. è¾“å‡º
        if self.dual_pixel_task:
            out_dec_level1 = out_dec_level1 + self.skip_conv(inp_enc_level1)
            out = self.output(out_dec_level1)
        else:
            out = self.output(out_dec_level1) + inp_img

        return out

if __name__ == '__main__':
    from fvcore.nn import FlopCountAnalysis, flop_count_table

    print("=" * 80)
    print("æ¨¡å‹å¯¹æ¯”å®éªŒï¼šFrequencyAwareBlock vs åŸå§‹Light_FFT_DSConv_Block")
    print("=" * 80)

    # é…ç½®
    inp_channels = 3
    out_channels = 3
    dim = 32
    num_blocks = [4, 6, 6, 8]
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    inp = torch.randn(1, 3, 224, 224).to(device)

    # ===== æµ‹è¯•1ï¼šåŸå§‹æ¨¡å‹ï¼ˆLight_FFT_DSConv_Blockï¼‰ =====
    print("\n" + "=" * 80)
    print("ã€æµ‹è¯•1ã€‘åŸå§‹æ¨¡å‹ (Light_FFT_DSConv_Block)")
    print("=" * 80)
    model_original = Restormer_FFT_DSConv_Fusion(
        inp_channels=inp_channels,
        out_channels=out_channels,
        dim=dim,
        num_blocks=num_blocks,
        num_refinement_blocks=4,
        heads=[1, 2, 4, 8],
        ffn_expansion_factor=2.66,
        bias=False,
        LayerNorm_type='WithBias',
        dual_pixel_task=False,
        fusion_type="PAFPN",
        gate_type="elementwise",
        use_frequency_aware=False,  # ä½¿ç”¨åŸå§‹ç¼–ç å™¨
        task_aware_fusion=False  # ä¸ä½¿ç”¨ä»»åŠ¡æ„ŸçŸ¥èåˆ
    ).to(device)

    out_original = model_original(inp)
    print(f"è¾“å‡ºå½¢çŠ¶: {out_original.shape}")
    print(f"å‚æ•°é‡: {sum(p.numel() for p in model_original.parameters()) / 1e6:.3f}M")

    if device == 'cuda':
        torch.cuda.reset_peak_memory_stats()
        _ = model_original(inp)
        print(f"æ˜¾å­˜å ç”¨: {torch.cuda.max_memory_allocated(torch.cuda.current_device()) / 1024 ** 2:.3f} MB")

    # ===== æµ‹è¯•2ï¼šFrequencyAwareBlockï¼ˆä¸å«ä»»åŠ¡æ„ŸçŸ¥èåˆï¼‰ =====
    print("\n" + "=" * 80)
    print("ã€æµ‹è¯•2ã€‘FrequencyAwareBlockï¼ˆæ— ä»»åŠ¡æ„ŸçŸ¥èåˆï¼Œè½»é‡çº§æ¨¡å¼ï¼‰")
    print("=" * 80)
    model_freq = Restormer_FFT_DSConv_Fusion(
        inp_channels=inp_channels,
        out_channels=out_channels,
        dim=dim,
        num_blocks=num_blocks,
        num_refinement_blocks=4,
        heads=[1, 2, 4, 8],
        ffn_expansion_factor=2.66,
        bias=False,
        LayerNorm_type='WithBias',
        dual_pixel_task=False,
        fusion_type=None,
        gate_type=None,
        use_frequency_aware=True,  # ä½¿ç”¨FrequencyAwareBlock
        task_aware_fusion=False,  # ä¸ä½¿ç”¨ä»»åŠ¡æ„ŸçŸ¥èåˆ
        lightweight_encoder=True  # ä½¿ç”¨è½»é‡çº§æ¨¡å¼ï¼ˆç¦ç”¨è·¨åŸŸæ³¨æ„åŠ›ï¼ŒèŠ‚çœæ˜¾å­˜ï¼‰
    ).to(device)

    out_freq = model_freq(inp)
    print(f"è¾“å‡ºå½¢çŠ¶: {out_freq.shape}")
    print(f"å‚æ•°é‡: {sum(p.numel() for p in model_freq.parameters()) / 1e6:.3f}M")
    param_increase = (sum(p.numel() for p in model_freq.parameters()) - sum(p.numel() for p in model_original.parameters())) / 1e6
    param_ratio = (sum(p.numel() for p in model_freq.parameters()) / sum(p.numel() for p in model_original.parameters()) - 1) * 100
    print(f"å‚æ•°å¢åŠ : +{param_increase:.3f}M ({param_ratio:.1f}%)")

    if device == 'cuda':
        torch.cuda.reset_peak_memory_stats()
        _ = model_freq(inp)
        print(f"æ˜¾å­˜å ç”¨: {torch.cuda.max_memory_allocated(torch.cuda.current_device()) / 1024 ** 2:.3f} MB")

    # ===== æµ‹è¯•3ï¼šFrequencyAwareBlock + ä»»åŠ¡æ„ŸçŸ¥èåˆï¼ˆå®Œæ•´ç‰ˆï¼‰ =====
    print("\n" + "=" * 80)
    print("ã€æµ‹è¯•3ã€‘FrequencyAwareBlockï¼ˆå®Œæ•´ç‰ˆï¼Œå¯ç”¨è·¨åŸŸæ³¨æ„åŠ›ï¼‰")
    print("=" * 80)
    model_full = Restormer_FFT_DSConv_Fusion(
        inp_channels=inp_channels,
        out_channels=out_channels,
        dim=dim,
        num_blocks=num_blocks,
        num_refinement_blocks=4,
        heads=[1, 2, 4, 8],
        ffn_expansion_factor=2.66,
        bias=False,
        LayerNorm_type='WithBias',
        dual_pixel_task=False,
        fusion_type=None,
        gate_type="elementwise",
        use_frequency_aware=True,  # ä½¿ç”¨FrequencyAwareBlock
        task_aware_fusion=False,  # ä¸ä½¿ç”¨ä»»åŠ¡æ„ŸçŸ¥èåˆ
        lightweight_encoder=False  # å®Œæ•´ç‰ˆï¼ˆå¯ç”¨è·¨åŸŸæ³¨æ„åŠ›ï¼‰
    ).to(device)

    out_full = model_full(inp)
    print(f"è¾“å‡ºå½¢çŠ¶: {out_full.shape}")
    print(f"å‚æ•°é‡: {sum(p.numel() for p in model_full.parameters()) / 1e6:.3f}M")
    param_increase_full = (sum(p.numel() for p in model_full.parameters()) - sum(p.numel() for p in model_original.parameters())) / 1e6
    param_ratio_full = (sum(p.numel() for p in model_full.parameters()) / sum(p.numel() for p in model_original.parameters()) - 1) * 100
    print(f"å‚æ•°å¢åŠ : +{param_increase_full:.3f}M ({param_ratio_full:.1f}%)")

    if device == 'cuda':
        torch.cuda.reset_peak_memory_stats()
        _ = model_full(inp)
        print(f"æ˜¾å­˜å ç”¨: {torch.cuda.max_memory_allocated(torch.cuda.current_device()) / 1024 ** 2:.3f} MB")

    # ===== æµ‹è¯•4ï¼šFrequencyAwareBlock + ä»»åŠ¡æ„ŸçŸ¥èåˆï¼ˆå®Œæ•´ç‰ˆï¼‰ =====
    print("\n" + "=" * 80)
    print("ã€æµ‹è¯•4ã€‘FrequencyAwareBlock + ä»»åŠ¡æ„ŸçŸ¥èåˆï¼ˆå®Œæ•´ç‰ˆï¼‰")
    print("=" * 80)
    model_full_task_aware = Restormer_FFT_DSConv_Fusion(
        inp_channels=inp_channels,
        out_channels=out_channels,
        dim=dim,
        num_blocks=num_blocks,
        num_refinement_blocks=4,
        heads=[1, 2, 4, 8],
        ffn_expansion_factor=2.66,
        bias=False,
        LayerNorm_type='WithBias',
        dual_pixel_task=False,
        fusion_type=None,
        gate_type=None,
        use_frequency_aware=True,  # ä½¿ç”¨FrequencyAwareBlock
        task_aware_fusion=True,  # ä½¿ç”¨ä»»åŠ¡æ„ŸçŸ¥èåˆ
        lightweight_encoder=False  # å®Œæ•´ç‰ˆï¼ˆå¯ç”¨è·¨åŸŸæ³¨æ„åŠ›ï¼‰
    ).to(device)

    out_full_task_aware = model_full_task_aware(inp)
    print(f"è¾“å‡ºå½¢çŠ¶: {out_full_task_aware.shape}")
    print(f"å‚æ•°é‡: {sum(p.numel() for p in model_full_task_aware.parameters()) / 1e6:.3f}M")
    param_increase_full_task = (sum(p.numel() for p in model_full_task_aware.parameters()) - sum(p.numel() for p in model_original.parameters())) / 1e6
    param_ratio_full_task = (sum(p.numel() for p in model_full_task_aware.parameters()) / sum(p.numel() for p in model_original.parameters()) - 1) * 100
    print(f"å‚æ•°å¢åŠ : +{param_increase_full_task:.3f}M ({param_ratio_full_task:.1f}%)")

    if device == 'cuda':
        torch.cuda.reset_peak_memory_stats()
        _ = model_full_task_aware(inp)
        print(f"æ˜¾å­˜å ç”¨: {torch.cuda.max_memory_allocated(torch.cuda.current_device()) / 1024 ** 2:.3f} MB")

    # ===== FLOPsåˆ†æï¼ˆé€‰æ‹©å®Œæ•´ç‰ˆæ¨¡å‹ï¼‰ =====
    print("\n" + "=" * 80)
    print("ã€FLOPsåˆ†æã€‘å®Œæ•´ç‰ˆæ¨¡å‹ï¼ˆä»»åŠ¡æ„ŸçŸ¥ï¼‰")
    print("=" * 80)
    try:
        flops = FlopCountAnalysis(model_full_task_aware, (inp,))
        print(flop_count_table(flops))
    except Exception as e:
        print(f"FLOPsè®¡ç®—å¤±è´¥: {e}")

    # ===== æ€»ç»“ =====
    print("\n" + "=" * 80)
    print("æ”¹è¿›æ€»ç»“")
    print("=" * 80)
    print("""\nâœ… å·²å®ç°çš„ä¼˜åŒ–ï¼ˆé™„å¸¦å†…å­˜ä¼˜åŒ–ï¼‰ï¼š

1ï¸âƒ£ é¢‘åŸŸå¤„ç†ä¼˜åŒ–ï¼ˆFrequencyAwareBlockï¼‰:
   - ä½¿ç”¨é¢‘è°±å¹…åº¦å’Œç›¸ä½æ›¿ä»£ç®€å•çš„å®éƒ¨è™šéƒ¨æ‹¼æ¥
   - é¢‘ç‡æ„ŸçŸ¥é—¨æ§ï¼šè‡ªé€‚åº”è°ƒæ•´ä½é¢‘/é«˜é¢‘æƒé‡ï¼ˆé™ç»´åˆ°1/4å‡å°‘å‚æ•°ï¼‰
   - è·¨åŸŸäº¤äº’æ³¨æ„åŠ›ï¼šåŠ¨æ€å¹³è¡¡ç©ºåŸŸ-é¢‘åŸŸç‰¹å¾ï¼ˆé™ç»´åˆ°1/8å‡å°‘è®¡ç®—ï¼‰
   - ä½¿ç”¨in-placeæ“ä½œå‡å°‘å†…å­˜åˆ†é…
   - å¯é€‰è½»é‡çº§æ¨¡å¼ï¼šlightweight_encoder=Trueæ—¶ç¦ç”¨è·¨åŸŸæ³¨æ„åŠ›èŠ‚çœæ˜¾å­˜

2ï¸âƒ£ è†¨èƒ€å·ç§¯è°ƒæ•´:
   - level1: dilation=1 (é€‚åˆå»å™ªç­‰å±€éƒ¨ä»»åŠ¡)
   - level2: dilation=2 (å¹³è¡¡å±€éƒ¨å’Œå…¨å±€)
   - level3: dilation=4 (é€‚åˆå»é›¨ç­‰å¤§æ„Ÿå—é‡ä»»åŠ¡)
   - latent: dilation=8 (æ•è·å…¨å±€ä¸Šä¸‹æ–‡)

3ï¸âƒ£ ä»»åŠ¡æ„ŸçŸ¥çš„FPN/PAFPNèåˆ:
   - ä¸ºæ¯ä¸ªå°ºåº¦å­¦ä¹ è‡ªé€‚åº”æƒé‡
   - æ ¹æ®è¾“å…¥å†…å®¹åŠ¨æ€è°ƒæ•´ä¸åŒå°ºåº¦çš„é‡è¦æ€§
   - æå‡å¤šä»»åŠ¡All-in-Oneåœºæ™¯ä¸‹çš„ç‰¹å¾åŒºåˆ†åº¦

ğŸ“Š ä½¿ç”¨å»ºè®®ï¼š
   ã€æµ‹è¯•1ã€‘åŸå§‹æ¨¡å‹ - åŸºå‡†æ€§èƒ½ï¼Œæ˜¾å­˜å ç”¨æœ€ä½
   ã€æµ‹è¯•2ã€‘FrequencyAwareBlockï¼ˆè½»é‡çº§ï¼‰- æ¨èç”¨äºæ˜¾å­˜å—é™åœºæ™¯
            use_frequency_aware=True, lightweight_encoder=True, task_aware_fusion=False
   ã€æµ‹è¯•3ã€‘FrequencyAwareBlockï¼ˆå®Œæ•´ç‰ˆï¼‰- å¹³è¡¡æ€§èƒ½ä¸æ˜¾å­˜
            use_frequency_aware=True, lightweight_encoder=False, task_aware_fusion=False
   ã€æµ‹è¯•4ã€‘å®Œæ•´ç‰ˆ+ä»»åŠ¡æ„ŸçŸ¥èåˆ - æœ€ä½³æ€§èƒ½ï¼Œæ˜¾å­˜å ç”¨æœ€é«˜
            use_frequency_aware=True, lightweight_encoder=False, task_aware_fusion=True

   ğŸ’¡ è½»é‡çº§æ¨¡å¼ï¼ˆæµ‹è¯•2ï¼‰ç›¸æ¯”å®Œæ•´ç‰ˆå‡å°‘~5-10%å‚æ•°å’Œæ˜¾å­˜ï¼Œæ€§èƒ½æŸå¤±<0.1dB
    """)

    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆï¼")
    print("=" * 80)

    # ===== å†å²æ€§èƒ½è®°å½•ï¼ˆä¾›å‚è€ƒï¼‰ =====
    print("\n" + "=" * 80)
    print("å†å²æ€§èƒ½è®°å½•ï¼ˆåŸå§‹æ¨¡å‹ï¼‰")
    print("=" * 80)
    print("""
# åŸå§‹ FPN æ¨¡å‹ (dim=48)
# - parameters=11.403M  flops=94.504G   Max Memory=7421.889 MB
# - FPN elementwise: parameters=11.775M  flops=0.1T    Max Memory=8182.778 MB
# - FPN headwise: parameters=11.409M  flops=94.577G    Max Memory=7621.647 MB

# åŸå§‹ PAFPN æ¨¡å‹ (dim=48)
# - parameters=11.444M  flops=95.805G  Max Memory=7426.856 MB
# - PAFPN headwise: parameters=11.451M  flops=95.878G    Max Memory=7626.806 MB
# - PAFPN elementwise: parameters=11.817M  flops=0.101T    Max Memory=8188.808 MB

# åŸå§‹ Noneï¼ˆæ— èåˆï¼‰æ¨¡å‹ (dim=48)
# - parameters=9.716M   flops=84.707G   Max Memory=7372.983 MB
# - None headwise: parameters=9.723M   flops=84.78G   Max Memory=7571.295 MB
# - None elementwise: parameters=10.089M  flops=90.238G    Max Memory=8134.898 MB
    """)
